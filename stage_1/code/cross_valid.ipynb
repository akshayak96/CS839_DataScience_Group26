{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SVM results----------------\n",
      "True Positives: 760\n",
      "True Negatives: 2435\n",
      "False Positives: 240\n",
      "False Negatives: 281\n",
      "Total number of data: 3716\n",
      "Accuracy: 0.85979547901\n",
      "Precision: 0.76\n",
      "Recall: 0.730067243036\n",
      "F1: 0.744732974032\n",
      "-----------------RF results----------------\n",
      "True Positives: 564\n",
      "True Negatives: 2574\n",
      "False Positives: 101\n",
      "False Negatives: 477\n",
      "Total number of data: 3716\n",
      "Accuracy: 0.844456404736\n",
      "Precision: 0.848120300752\n",
      "Recall: 0.541786743516\n",
      "F1: 0.661195779601\n",
      "-----------------DT results----------------\n",
      "True Positives: 796\n",
      "True Negatives: 2475\n",
      "False Positives: 200\n",
      "False Negatives: 245\n",
      "Total number of data: 3716\n",
      "Accuracy: 0.880247578041\n",
      "Precision: 0.799196787149\n",
      "Recall: 0.7646493756\n",
      "F1: 0.781541482572\n",
      "-----------------LogR results----------------\n",
      "True Positives: 745\n",
      "True Negatives: 2462\n",
      "False Positives: 213\n",
      "False Negatives: 296\n",
      "Total number of data: 3716\n",
      "Accuracy: 0.863024757804\n",
      "Precision: 0.777661795407\n",
      "Recall: 0.715658021134\n",
      "F1: 0.745372686343\n",
      "-----------------LinearR results----------------\n",
      "True Positives: 1032\n",
      "True Negatives: 603\n",
      "False Positives: 2072\n",
      "False Negatives: 9\n",
      "Total number of data: 3716\n",
      "Accuracy: 0.439989235737\n",
      "Precision: 0.332474226804\n",
      "Recall: 0.991354466859\n",
      "F1: 0.49794933655\n",
      "\n",
      "\n",
      "Best classifier M --> Decision Tree\n",
      "F1: 0.781541482572\n",
      "Precision: 0.799196787149\n",
      "Recall: 0.7646493756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenamilkai/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/elenamilkai/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/base.py:485: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def accuracy(pred, ground_truth):\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    total = len(pred)\n",
    "    for i in range(0, total):\n",
    "        if pred[i] == 1 and ground_truth[i] == 1:\n",
    "            tp += 1\n",
    "        elif pred[i] == 1 and ground_truth[i] == 0:\n",
    "            fp += 1\n",
    "        elif pred[i] == 0 and ground_truth[i] == 0:\n",
    "            tn += 1\n",
    "        elif pred[i] == 0 and ground_truth[i] == 1:\n",
    "            fn += 1\n",
    "\n",
    "    accuracy = (tp + tn) / total\n",
    "\n",
    "    if tp == 0 and fp == 0:\n",
    "        precision = -1\n",
    "        recall = -1\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    print(\"True Positives: {}\".format(tp))\n",
    "    print(\"True Negatives: {}\".format(tn))\n",
    "    print(\"False Positives: {}\".format(fp))\n",
    "    print(\"False Negatives: {}\".format(fn))\n",
    "    print(\"Total number of data: {}\".format(total))\n",
    "\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    print(\"Precision: {}\".format(precision))\n",
    "    print(\"Recall: {}\".format(recall))\n",
    "    print(\"F1: {}\".format(f1))\n",
    "    \n",
    "    return f1, precision, recall\n",
    "\n",
    "# cross validation\n",
    "trainX = pd.read_csv('results/train/features.csv', sep=',', index_col=0).values\n",
    "trainY = pd.read_csv('results/train/labels.csv', sep=',', index_col=0, header=None).values.flatten()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainX, trainY, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=5).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "pred = clf.predict(X_test)\n",
    "print('-----------------SVM results----------------')\n",
    "accuracy(pred, y_test)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=5, random_state=0).fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print('-----------------RF results----------------')\n",
    "accuracy(pred, y_test)\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\", random_state=0).fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print('-----------------DT results----------------')\n",
    "F1, Precision, Recall = accuracy(pred, y_test)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(fit_intercept=True).fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print('-----------------LogR results----------------')\n",
    "accuracy(pred, y_test)\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "p = reg.predict(X_test)\n",
    "pred = []\n",
    "for i in range(0, len(p)):\n",
    "    if p[i] > 0:\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)\n",
    "print('-----------------LinearR results----------------')\n",
    "accuracy(pred, y_test)\n",
    "\n",
    "print('\\n')\n",
    "print'Best classifier M --> Decision Tree'\n",
    "print 'F1:', F1\n",
    "print 'Precision:', Precision\n",
    "print 'Recall:', Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
